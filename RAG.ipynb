{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d6334d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7fcbb04",
   "metadata": {},
   "source": [
    "To master **Retrieval-Augmented Generation (RAG)** using LangChain, a structured learning path can be highly beneficial. Below is a comprehensive syllabus designed to guide you through the essential concepts and practical implementations:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Introduction to Retrieval-Augmented Generation (RAG)**\n",
    "\n",
    "- **Concepts:**\n",
    "  - Understanding the limitations of standalone Large Language Models (LLMs).\n",
    "  - The role of external data retrieval in enhancing LLM responses.\n",
    "  - Overview of the RAG architecture and its components.\n",
    "\n",
    "- **Resources:**\n",
    "  - [Retrieval augmented generation (RAG) - LangChain Documentation](https://python.langchain.com/docs/concepts/rag/)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Fundamentals of LangChain**\n",
    "\n",
    "- **Concepts:**\n",
    "  - Introduction to LangChain and its capabilities.\n",
    "  - Core components: Models, Prompts, Parsers, and Chains.\n",
    "  - Integrating LangChain with various data sources and APIs.\n",
    "\n",
    "- **Resources:**\n",
    "  - [LangChain for LLM Application Development - DeepLearning.AI](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Building a Basic RAG Application with LangChain**\n",
    "\n",
    "- **Concepts:**\n",
    "  - Setting up the development environment.\n",
    "  - Loading and preprocessing textual data.\n",
    "  - Implementing a simple Q&A system using LangChain.\n",
    "\n",
    "- **Practical Exercise:**\n",
    "  - Develop a basic RAG application that answers questions based on a provided text corpus.\n",
    "\n",
    "- **Resources:**\n",
    "  - [Build a Retrieval Augmented Generation (RAG) App: Part 1](https://python.langchain.com/docs/tutorials/rag/)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Advanced RAG Techniques**\n",
    "\n",
    "- **Concepts:**\n",
    "  - Enhancing retrieval accuracy with advanced indexing methods.\n",
    "  - Implementing semantic search and vector databases.\n",
    "  - Reducing hallucinations in AI outputs and improving response reliability.\n",
    "\n",
    "- **Practical Exercise:**\n",
    "  - Integrate a vector database like FAISS or Weaviate to improve document retrieval.\n",
    "\n",
    "- **Resources:**\n",
    "  - [Retrieval Augmented Generation LlamaIndex & LangChain Course](https://learn.activeloop.ai/courses/rag)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Integrating External Data Sources**\n",
    "\n",
    "- **Concepts:**\n",
    "  - Connecting LangChain applications to APIs and external databases.\n",
    "  - Handling unstructured data from various formats (PDFs, CSVs, etc.).\n",
    "  - Ensuring data privacy and security during retrieval.\n",
    "\n",
    "- **Practical Exercise:**\n",
    "  - Build a RAG system that retrieves and utilizes information from live web sources.\n",
    "\n",
    "- **Resources:**\n",
    "  - [Retrieval Augmented Generation (RAG) with LangChain - DataCamp](https://www.datacamp.com/courses/retrieval-augmented-generation-rag-with-langchain)\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Optimizing and Evaluating RAG Systems**\n",
    "\n",
    "- **Concepts:**\n",
    "  - Techniques for evaluating the performance of RAG applications.\n",
    "  - Implementing feedback loops for continuous improvement.\n",
    "  - Balancing response generation speed and accuracy.\n",
    "\n",
    "- **Practical Exercise:**\n",
    "  - Set up evaluation metrics and conduct performance testing on your RAG application.\n",
    "\n",
    "- **Resources:**\n",
    "  - [Advanced LangChain Techniques: Mastering RAG Applications](https://www.udemy.com/course/advanced-langchain-techniques-mastering-rag-applications/)\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Deploying RAG Applications**\n",
    "\n",
    "- **Concepts:**\n",
    "  - Preparing RAG systems for production environments.\n",
    "  - Scalability considerations and cloud deployment options.\n",
    "  - Monitoring and maintaining deployed applications.\n",
    "\n",
    "- **Practical Exercise:**\n",
    "  - Deploy your RAG application using a platform like Streamlit or Flask.\n",
    "\n",
    "- **Resources:**\n",
    "  - [LangChain: Chat with Your Data - DeepLearning.AI](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Case Studies and Real-World Applications**\n",
    "\n",
    "- **Concepts:**\n",
    "  - Exploring industry use cases of RAG systems.\n",
    "  - Lessons learned from deploying RAG in production.\n",
    "  - Future trends and developments in RAG technology.\n",
    "\n",
    "- **Resources:**\n",
    "  - [Retrieval Augmented Generation for LLM Bots with LangChain](https://www.activeloop.ai/resources/retrieval-augmented-generation-for-llm-bots-with-lang-chain/)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df3fb7",
   "metadata": {},
   "source": [
    "## Overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d87a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\rag\\rag\\lib\\site-packages (0.3.20)\n",
      "Requirement already satisfied: langchainhub in c:\\rag\\rag\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: chromadb in c:\\rag\\rag\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\rag\\rag\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (0.3.49)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (0.3.21)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (0.3.19)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\rag\\rag\\lib\\site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\rag\\rag\\lib\\site-packages (from langchainhub) (24.2)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in c:\\rag\\rag\\lib\\site-packages (from langchainhub) (2.32.0.20250328)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (2.11.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi==0.115.9 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\rag\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (3.23.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (4.13.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\rag\\rag\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (3.10.16)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\rag\\rag\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\rag\\rag\\lib\\site-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\rag\\rag\\lib\\site-packages (from langchain-huggingface) (0.29.3)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\rag\\rag\\lib\\site-packages (from langchain-huggingface) (4.0.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\rag\\rag\\lib\\site-packages (from langchain-huggingface) (4.50.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\rag\\rag\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\rag\\rag\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\rag\\rag\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\rag\\rag\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio in c:\\rag\\rag\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\rag\\rag\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\rag\\rag\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\rag\\rag\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\rag\\rag\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\rag\\rag\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2025.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\rag\\rag\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\rag\\rag\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\rag\\rag\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\rag\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\rag\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\rag\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\rag\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\rag\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\rag\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\rag\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\rag\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\rag\\rag\\lib\\site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (0.3.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\rag\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\rag\\rag\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\rag\\rag\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\rag\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\rag\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\rag\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: sympy in c:\\rag\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.1 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b1 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\rag\\rag\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\rag\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\rag\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\rag\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\rag\\rag\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\rag\\rag\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\rag\\rag\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\rag\\rag\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\rag\\rag\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\rag\\rag\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\rag\\rag\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\rag\\rag\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\rag\\rag\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\rag\\rag\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.15.2)\n",
      "Requirement already satisfied: Pillow in c:\\rag\\rag\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\rag\\rag\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\rag\\rag\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\rag\\rag\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\rag\\rag\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\rag\\rag\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\rag\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\rag\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\rag\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\rag\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\rag\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\rag\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\rag\\rag\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\rag\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\rag\\rag\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\rag\\rag\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: networkx in c:\\rag\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\rag\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\rag\\rag\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\rag\\rag\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\rag\\rag\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\rag\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\rag\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\rag\\rag\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\rag\\rag\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\rag\\rag\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "## important packages\n",
    "! pip install  langchain_community langchainhub chromadb  langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "639d29cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI messages:Hi there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "#check the setup \n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "load_dotenv()\n",
    "\n",
    "#API key for Groq\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "#model init\n",
    "LLM=ChatGoogleGenerativeAI(\n",
    "    api_key=api_key,\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "#response from MOdel like llama model , Deepseek R1, etc.\n",
    "response=LLM.invoke(\"hi\")\n",
    "\n",
    "# just Print the messages from AI and Dissplay\n",
    "print(f'AI messages:{response.content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5291f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24e719b4",
   "metadata": {},
   "source": [
    "# Quickstart RAG\n",
    "## ( Retrival Augmented Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f74ed19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import important liberay\n",
    "import bs4 \n",
    "#prebulid prompt\n",
    "from langchain import hub\n",
    "# chunking the sentence for efficient model can process easly\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# webbaseloader load any wedpage content\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "# vectorestores likes fassi,chroma in memeory database\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#handling of outputs from language models (LLMs) by converting them into a straightforward string forma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# RunnablePassthrough class in LangChain serves as a utility that forwards its input directly to its output without modification, effectively acting as an identity function.\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "#model init already Done\n",
    "# from langchain_groq import ChatGroq \n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Indexing \n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://python.langchain.com/docs/how_to/document_loader_web/\",), #raw html page\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "#load the doc\n",
    "doc=loader.load() #load format is list use for loop display\n",
    "\n",
    "\n",
    "#split\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "\n",
    "splits=text_splitter.split_documents(doc)\n",
    "\n",
    "#Embedding\n",
    "#pip install sentence-transformers \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842edfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicky\\AppData\\Local\\Temp\\ipykernel_3496\\1406486093.py:11: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorestore.persist()\n"
     ]
    }
   ],
   "source": [
    "#embedding model to convert text to vector\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "#initialize the vector store\n",
    "if splits:\n",
    "    vectorestore = Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=\"./news_vectors\"\n",
    "    )\n",
    "    vectorestore.persist()\n",
    "else:\n",
    "    print(\"No documents to embed — check source or content filtering.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d02d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the vector store to disk\n",
    "vectorestore = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./news_vectors\"\n",
    ")\n",
    "\n",
    "retriever=vectorestore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd7146bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt template\n",
    "\n",
    "prompt = \"\"\"\n",
    "   You are an intelligent assistant with access to relevant documents retrieved from a trusted knowledge base.\n",
    "\n",
    "Instructions:\n",
    "- Use ONLY the information provided in the context.\n",
    "- Think step-by-step and reason through the content.\n",
    "- Cite specific facts or lines from the context if needed.\n",
    "- If the answer is not clearly supported by the context, say: \"The answer is not available in the provided documents.\"\n",
    "- Respond clearly and concisely. Use bullet points or short paragraphs if needed.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    ":\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a70be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#post-processing\n",
    "def format_doc(docs):\n",
    "    return\"\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b3530b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'dict' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m rag_chain = (\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRunnablePassthrough\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[32m      4\u001b[39m     | LLM\n\u001b[32m      5\u001b[39m     | StrOutputParser()\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m response = rag_chain.invoke(\n\u001b[32m      9\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWhat is LangChain?\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for |: 'dict' and 'str'"
     ]
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_doc, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | LLM\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = rag_chain.invoke(\n",
    "    {\"question\": \"What is LangChain?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69766d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FAISS (Facebook AI Similarity Search) is a library that operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution. It applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. FAISS is used for similarity search, allowing for efficient nearest neighbor searches in high-dimensional spaces.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db04ab36",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected metadata value to be a str, int, float or bool, got ['eng'] which is a list in upsert.\n\nTry filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:95\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:419\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_upsert_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[43mvalidate_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# Prepare\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\types.py:251\u001b[39m, in \u001b[36mvalidate_insert_record_set\u001b[39m\u001b[34m(record_set)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[33m\"\u001b[39m\u001b[33mmetadatas\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     \u001b[43mvalidate_metadatas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadatas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\types.py:726\u001b[39m, in \u001b[36mvalidate_metadatas\u001b[39m\u001b[34m(metadatas)\u001b[39m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m metadatas:\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m     \u001b[43mvalidate_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metadatas\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\types.py:692\u001b[39m, in \u001b[36mvalidate_metadata\u001b[39m\u001b[34m(metadata)\u001b[39m\n\u001b[32m    691\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m692\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    693\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected metadata value to be a str, int, float or bool, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m which is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    694\u001b[39m         )\n\u001b[32m    695\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "\u001b[31mValueError\u001b[39m: Expected metadata value to be a str, int, float or bool, got ['eng'] which is a list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:299\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:336\u001b[39m, in \u001b[36mCollection.upsert\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[32m    326\u001b[39m \n\u001b[32m    327\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    334\u001b[39m \u001b[33;03m    None\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m upsert_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_upsert_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28mself\u001b[39m._client._upsert(\n\u001b[32m    346\u001b[39m     collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m    347\u001b[39m     ids=upsert_request[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m     database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    354\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:98\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg).with_traceback(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:95\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:419\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_upsert_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[43mvalidate_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# Prepare\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\types.py:251\u001b[39m, in \u001b[36mvalidate_insert_record_set\u001b[39m\u001b[34m(record_set)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[33m\"\u001b[39m\u001b[33mmetadatas\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     \u001b[43mvalidate_metadatas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadatas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\types.py:726\u001b[39m, in \u001b[36mvalidate_metadatas\u001b[39m\u001b[34m(metadatas)\u001b[39m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m metadatas:\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m     \u001b[43mvalidate_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metadatas\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\chromadb\\api\\types.py:692\u001b[39m, in \u001b[36mvalidate_metadata\u001b[39m\u001b[34m(metadata)\u001b[39m\n\u001b[32m    691\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m692\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    693\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected metadata value to be a str, int, float or bool, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m which is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    694\u001b[39m         )\n\u001b[32m    695\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "\u001b[31mValueError\u001b[39m: Expected metadata value to be a str, int, float or bool, got ['eng'] which is a list in upsert.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[170]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m splits = spliter.split_documents(doc)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# cleaned_docs = clean_metadata(splits)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m vectorstore1 = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchroma_db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     32\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m vectorstore1.persist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    886\u001b[39m metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:843\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m    838\u001b[39m         api=chroma_collection._client,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    839\u001b[39m         ids=ids,\n\u001b[32m    840\u001b[39m         metadatas=metadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    841\u001b[39m         documents=texts,\n\u001b[32m    842\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    849\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\RAG\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:311\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected metadata value to be\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[32m    307\u001b[39m     msg = (\n\u001b[32m    308\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTry filtering complex metadata from the document using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlangchain_community.vectorstores.utils.filter_complex_metadata.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    310\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e.args[\u001b[32m0\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + msg)\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[31mValueError\u001b[39m: Expected metadata value to be a str, int, float or bool, got ['eng'] which is a list in upsert.\n\nTry filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata."
     ]
    }
   ],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "page_url = \"https://en.wikipedia.org/wiki/Portal:Current_events\"\n",
    "loader = UnstructuredLoader(web_url=page_url)\n",
    "\n",
    "\n",
    "doc=loader.load() #load format is list use for loop display\n",
    "\n",
    "spliter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "splits=spliter.split_documents(doc)\n",
    "\n",
    "#embedding model to convert text to vector\n",
    "def clean_metadata(documents):\n",
    "    for doc in documents:\n",
    "        for key, value in doc.metadata.items():\n",
    "            if isinstance(value, list):\n",
    "                # Convert list to comma-separated string\n",
    "                doc.metadata[key] = \", \".join(map(str, value))\n",
    "            elif isinstance(value, dict):\n",
    "                # Optional: flatten nested dicts if needed\n",
    "                doc.metadata[key] = str(value)\n",
    "    return documents\n",
    "\n",
    "\n",
    "splits = spliter.split_documents(doc)\n",
    "cleaned_docs = clean_metadata(splits)\n",
    "\n",
    "vectorstore1 = Chroma.from_documents(\n",
    "    documents=cleaned_docs,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"chroma_db\"\n",
    ")\n",
    "\n",
    "vectorstore1.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b01414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever=vectorstore1.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"Use the following context to answer the question at the end.\n",
    "If you don't know the answer, just say you don't know – don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#post-processing\n",
    "def format_doc(docs):\n",
    "    return\"\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "#chain\n",
    "\n",
    "rag_chain=(\n",
    "    {\"context\": retriever |format_doc,\"question\":RunnablePassthrough()}\n",
    "    | prompt_teemplate\n",
    "    | LLM\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response=rag_chain.invoke(\"what is FAISS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de708b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'dict' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[167]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m rag_chain = (\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43m{\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_doc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRunnablePassthrough\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_template\u001b[49m\n\u001b[32m      7\u001b[39m     | LLM\n\u001b[32m      8\u001b[39m     | StrOutputParser()\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m response = rag_chain.invoke(\u001b[33m\"\u001b[39m\u001b[33mwhat is FAISS\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for |: 'dict' and 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_doc,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt_template\n",
    "    | LLM\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = rag_chain.invoke(\"what is FAISS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8c9804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import important library\n",
    "import bs4 \n",
    "#prebulid prompt\n",
    "from langchain import hub\n",
    "# chunking the sentence for efficient model can process easly\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# webbaseloader load any wedpage content\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "# vectorestores likes fassi,chroma in memeory database\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#handling of outputs from language models (LLMs) by converting them into a straightforward string forma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# RunnablePassthrough class in LangChain serves as a utility that forwards its input directly to its output without modification, effectively acting as an identity function.\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "#model init already Done\n",
    "# from langchain_groq import ChatGroq \n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "#load the pdf file\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "#FAISS is a library for efficient similarity search and clustering of dense vectors.\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "#Follow the below steps to load the pdf file and create a vector store\n",
    "#install the required library\n",
    "\n",
    "#load the pdf file\n",
    "loader=PyPDFLoader(\"TensorFlow Guide.pdf\")\n",
    "\n",
    "doc=loader.load() #load format is list use for loop display\n",
    "\n",
    "#split the doc into chunks\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "splits=text_splitter.split_documents(doc)\n",
    "\n",
    " \n",
    "#embedding model to convert text to vector\n",
    "#Before using this model, make sure to install the sentence-transformers library.\n",
    "#pip install sentence-transformers\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "#initialize the vector store\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "\n",
    "#retrievering from the vector store with top 3 results search type mmr (maximal marginal relevance)\n",
    "retriever=vectorstore.as_retriever(search_type='mmr',search_Kwargs={'k':3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "488a0000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\RAG\\RAG\\Lib\\site-packages\\langsmith\\client.py:277: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prebuilt prompt template\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "#post-processing list of documents to string\n",
    "def format_doc(docs):\n",
    "    return\"\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "#langchain chain expression sequence of operations to be performed on the input data\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_doc, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | LLM\n",
    "    | StrOutputParser())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "638aa4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output\n",
    "\n",
    "query=input(\"Enter your query:\") #what is tensorflow and how it works\n",
    "response=rag_chain.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc9b5a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your query is: what is tensorflow and how it works\n",
      "AI messages:TensorFlow is a powerful ecosystem that unlocks potential in computation and innovation. It delegates tasks across CPUs, GPUs, or multiple devices, improving computational speed and efficiency. TensorFlow also uses components like TensorFlow Data Validation (TFDV) and TensorFlow Transform (TFT) to validate data quality and appropriateness.\n"
     ]
    }
   ],
   "source": [
    "print(f'Your query is: {query}')\n",
    "print(f'AI messages:{response}') #AI message is the final output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647a5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
